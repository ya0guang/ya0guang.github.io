<!doctype html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="generator" content="TiddlyWiki" />
<meta name="tiddlywiki-version" content="5.3.3" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="mobile-web-app-capable" content="yes"/>
<meta name="format-detection" content="telephone=no">
<link id="faviconLink" rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="static.css">
<title>LLM (for) Security: ya0guang's notebook — Personality Backup</title>
</head>
<body class="tc-body">

<section class="tc-story-river tc-static-story-river">
<p><div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists  tc-tagged-LLM tc-tagged-Research tc-tagged-Security tc-tagged-Analysis" data-tags="LLM Research Security Analysis" data-tiddler-title="LLM (for) Security" role="article"><div class="tc-tiddler-title"><div class="tc-titlebar"><span class="tc-tiddler-controls"><button aria-expanded="false" aria-label="more" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div><button aria-label="edit" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button><button aria-label="close" class="tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span><h2 class="tc-title">LLM (for) Security</h2></span></div><div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div></div><div class="tc-reveal"></div><div class=" tc-reveal"><div class="tc-subtitle"><a class="tc-tiddlylink tc-tiddlylink-missing" href=".html"></a> October 29, 2023 at 9:19 pm</div></div><div class=" tc-reveal"><div class="tc-tags-wrapper"><span class="tc-tag-list-item" data-tag-title="Analysis"><span aria-expanded="false" class="tc-tag-label tc-btn-invisible" draggable="true" style="fill:rgb(38, 38, 38);color:rgb(38, 38, 38);">Analysis</span><span class="tc-drop-down tc-reveal" hidden="true"></span></span><span class="tc-tag-list-item" data-tag-title="LLM"><span aria-expanded="false" class="tc-tag-label tc-btn-invisible" draggable="true" style="fill:rgb(38, 38, 38);color:rgb(38, 38, 38);">LLM</span><span class="tc-drop-down tc-reveal" hidden="true"></span></span><span class="tc-tag-list-item" data-tag-title="Research"><span aria-expanded="false" class="tc-tag-label tc-btn-invisible" draggable="true" style="fill:rgb(38, 38, 38);color:rgb(38, 38, 38);">Research</span><span class="tc-drop-down tc-reveal" hidden="true"></span></span><span class="tc-tag-list-item" data-tag-title="Security"><span aria-expanded="false" class="tc-tag-label tc-btn-invisible" draggable="true" style="fill:rgb(38, 38, 38);color:rgb(38, 38, 38);">Security</span><span class="tc-drop-down tc-reveal" hidden="true"></span></span></div></div><div class="tc-tiddler-body tc-reveal"><h1 class="">Meta Research</h1><ul><li><a class="tc-tiddlylink-external" href="https://llmsecurity.net/" rel="noopener noreferrer" target="_blank">LLM Security</a>; twitter <a class="tc-tiddlylink-external" href="https://twitter.com/llm_sec" rel="noopener noreferrer" target="_blank">@llm_sec</a></li></ul><h1 class="">Technical Reports</h1><ul><li><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/2303.08774.pdf" rel="noopener noreferrer" target="_blank">GPT-4 Technical Report</a></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="CodeT5%252B%253A%2520Open%2520Code%2520Large%2520Language%2520Models%2520for%2520Code%2520Understanding%2520and%2520Generation.html">CodeT5+: Open Code Large Language Models for Code Understanding and Generation</a></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Tree%2520of%2520Thoughts%253A%2520Deliberate%2520Problem%2520Solving%2520with%2520Large%2520Language%2520Models.html">Tree of Thoughts: Deliberate Problem Solving with Large Language Models</a></li></ul><h1 class="">LLM for Security</h1><h2 class="">Fuzzing</h2><ul><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Large%2520Language%2520Models%2520are%2520Zero-Shot%2520Fuzzers%253A%2520Fuzzing%2520Deep-Learning%2520Libraries%2520via%2520Large%2520Language%2520Models.html">Large Language Models are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models</a></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Large%2520Language%2520Models%2520are%2520Edge-Case%2520Fuzzers%253A%2520Testing%2520Deep%2520Learning%2520Libraries%2520via%2520FuzzGPT.html">Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT</a></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Large%2520Language%2520Models%2520for%2520Fuzzing%2520Parsers%2520%2528Registered%2520Report%2529.html">Large Language Models for Fuzzing Parsers (Registered Report)</a></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Universal%2520Fuzzing%2520via%2520Large%2520Language%2520Models.html">Universal Fuzzing via Large Language Models</a></li></ul><h2 class="">Program Repair</h2><ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="A%2520New%2520Era%2520in%2520Software%2520Security%253A%2520Towards%2520Self-Healing%2520Software%2520via%2520Large%2520Language%2520Models%2520and%2520Formal%2520Verification.html">A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="InferFix%253A%2520End-to-End%2520Program%2520Repair%2520with%2520LLMs%2520over%2520Retrieval-Augmented%2520Prompts.html">InferFix: End-to-End Program Repair with LLMs over Retrieval-Augmented Prompts</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Frustrated%2520with%2520Code%2520Quality%2520Issues%253F%2520LLMs%2520can%2520Help%2521.html">Frustrated with Code Quality Issues? LLMs can Help!</a></li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="Examining%2520Zero-Shot%2520Vulnerability%2520Repair%2520with%2520Large%2520Language%2520Models.html">Examining Zero-Shot Vulnerability Repair with Large Language Models</a></li></ul><h2 class="">Code Analysis</h2><ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="The%2520Hitchhiker%25E2%2580%2599s%2520Guide%2520to%2520Program%2520Analysis%253A%2520A%2520Journey%2520with%2520Large%2520Language%2520Models.html">The Hitchhiker’s Guide to Program Analysis: A Journey with Large Language Models</a></li></ul><h2 class="">Test Geenration</h2><ul><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="Large%2520Language%2520Models%2520are%2520Few-shot%2520Testers%253A%2520Exploring%2520LLM-based%2520General%2520Bug%2520Reproduction.html">Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction</a></li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="An%2520Empirical%2520Evaluation%2520of%2520Using%2520Large%2520Language%2520Models%2520for%2520Automated%2520Unit%2520Test%2520Generation.html">An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation</a></li></ul><h2 class="">MISC</h2><ul><li><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/2210.02506.pdf" rel="noopener noreferrer" target="_blank">Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors</a></li></ul></div>
</div></p>
</section>
</body>
</html>

