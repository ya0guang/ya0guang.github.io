---
layout: single
title: GPUTEE从入门到升天（尚未升天）
date: 2023-08-18 10:10:07
categories: "Tech"
tags:
- Research
- CS
- Linux Kernel
- SGX
header:
  teaser: 
---

从零开始一个H100 GPUTEE的配置，顺便体会做Artifact Evaluation的痛苦。这里主要记录踩坑，文档里面有的东西不再赘述。我对于VM和GPU的知识基本等于空白，搞了两天终于卡在了需要NVIDIA支持的地方上了。

## 参考资料

- [Confidential Computing Deployment Guide](https://docs.nvidia.com/confidential-computing-deployment-guide.pdf)
- [CUDA Installation Guide](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/contents.html)
- [GitHub: AMDSEV](https://github.com/AMDESE/AMDSEV)

## System Setting

我用的server是一块H100，两颗EPYC 914，坐落在ASUS ESC8000A-E12这架服务器上。

## BIOS

大多数BIOS现在似乎都是支持SEV（SEV-SNP）的了，按照文档enable或者设置就好了。但是文档里面有个小坑：还需要enable IOMMU。
这是为了能够把PCIe device pass through到VM里面。

## Host Side

基本上就是按照文档中的步骤去build一个5.19 customized kernel。
这一步基本上不会有什么问题，但这里有一个东西可能会在build之后的kernel中缺失：`vfio-pci`。
这个问题虽然不是很大，但是文档里面并没有说，我走了很多弯路才知道怎么搞定它。
先说结论：直接`sudo modprobe vfio-pci`即可。
找了很多网上setup vfio的说明，其中一个经典的方法是在`/etc/default/grub`的`GRUB_CMDLINE_LINUX_DEFAULT`里面加上`amd_iommu=on iommu=pt`。
这没有大错误。但是坑爹的地方在于SNP初始化的时候不允许IOMMU设置成`pt`（pass throhgh）。
善用dmesg来发现问题。

除此之外一个奇怪的点是H100的device ID在文档中写的是`2336`，然而实际上我拿到的是`2331`。
这里可能是工程机和量产机的区别，可以不必深究。
不过谨记在后续的步骤中使用正确的device ID。

## Guest Side

文档最坑爹的地方来了。
它使用了`Ubuntu 22.04.2 LTS`的系统，并贴上了一个下崽链接。
然而这个链接完全不work，在Ubuntu的官网上也很难找到这个版本，因为现在(2023.08.18)的版本是`22.04.3 LTS`。
我想着，就差一个minor minor version，应该问题不大。
事实证明我大错特错，在Guest里面反复装了driver一万次都是没法看到GPU。
后来突然意识到这个问题，换成了`22.04.2 LTS`再来一次。
当然还是无法work。不知道是不是在安装的时候已经完成了kernel升级，我进入系统的时候kernel已经变成了`6.2`，然而Guest的kernel版本应该是`5.19`。
于是乎再折腾一波，终于搞定。

神奇师弟给了我两个链接方便地吓到了kernel和年轻的Ubuntu：

- [Old Ubuntus](https://old-releases.ubuntu.com/releases/)
- [一键安装kernel](https://github.com/pimlie/ubuntu-mainline-kernel.sh)

## NVIDIA Firmware

当我以为一切都搞定的时候，发现Firmware版本不对了。
大抵是GPU买早了，文档中用了更新的版本。
等待NVIDIA答复，寄。

## 一些吐槽

1. NVIDIA的[repo中的文档](https://github.com/NVIDIA/nvtrust/blob/main/docs/deployment_guide.pdf)和[官网的文档](https://docs.nvidia.com/confidential-computing-deployment-guide.pdf)是不一样的！！！！
